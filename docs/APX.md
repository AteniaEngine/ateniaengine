# Atenia Engine ‚Äî APX Modes

## üü¶ APX 6.9 / 6.10 ‚Äî Fusion Profiling & Selector

- ‚úî Introducen un `FusionSelector` global que mide tiempos de rutas fusionadas vs no fusionadas (ej. FusedQKV).
- ‚úî Registran m√©tricas por tipo de fusi√≥n (tiempos unfused vs fused) y derivan una preferencia global.
- ‚úî No cambian los kernels base de MatMul/Linear/Attention; s√≥lo deciden cu√°ndo usar las variantes fusionadas existentes.
- ‚úî Integrados de forma transparente en `Graph::execute` y en la ruta de Self-Attention.

**DISCLAIMER APX 6.9 / 6.10 ‚Äî Fusion Profiling & Selector**

APX 6.9/6.10 no introducen nuevos kernels ni cambian la matem√°tica de los ya existentes. Su objetivo es medir, de forma estructural, el coste relativo de ejecutar ciertos patrones de manera fusionada (por ejemplo, FusedQKV) frente a la ruta naive separada, y almacenar estas estad√≠sticas en un selector global. Las decisiones derivadas afectan √∫nicamente a qu√© variante de kernel se llama (fusionada o no), pero siempre respetando las mismas ecuaciones y la misma sem√°ntica de forward/backward. La cinta de autograd y la representaci√≥n de tensores permanecen inalteradas.

---
## üü¶ APX 6.11 / 6.12 ‚Äî Runtime Policy & Scheduling Bias

- ‚úî Derivan una pol√≠tica de ejecuci√≥n global (`FusionRuntimePolicy`) a partir de las estad√≠sticas de 6.9/6.10.
- ‚úî APX 6.11 fija una pol√≠tica determinista (PreferFull / PreferQKV / Baseline) usada como hint global.
- ‚úî APX 6.12 a√±ade un sesgo de scheduling (`AdaptiveScheduleBias`) para influir en planificadores posteriores.
- ‚úî No modifican computaci√≥n real, s√≥lo establecen flags/hints de alto nivel.

**DISCLAIMER APX 6.11 / 6.12 ‚Äî Runtime Policy & Bias**

APX 6.11/6.12 no a√±aden nuevos kernels ni modifican la matem√°tica de los existentes. La pol√≠tica global y el sesgo de scheduling se usan exclusivamente como hints para seleccionadores posteriores (fusiones, orden de ejecuci√≥n), sin tocar los valores de los tensores ni la estructura del grafo. Todas las rutas siguen produciendo resultados num√©ricamente equivalentes dentro de los umbrales validados, y la cinta de autograd no se ve afectada.

---

- ‚úî Detecta autom√°ticamente la carga real del sistema (uso de CPU, hilos disponibles) en tiempo de ejecuci√≥n.
- ‚úî Ajusta din√°micamente el paralelismo efectivo del MatMul: n√∫mero de hilos utilizados por el scheduler PEX/WS y estrategia preferida (Seq / PEX / WS).
- ‚úî Aprovecha APX 7.2/7.3 para delegar en PGL cuando no hay una preferencia fuerte dictada por la carga externa.
- ‚úî Integrado en el scheduler PEX v2 y en la rama 6.3B del dispatcher para modos `ATENIA_APX_MODE >= "7.4"`.
- ‚úî Tests espec√≠ficos que simulan estados de carga alta/media/baja y bench ligero de diagn√≥stico.

**DISCLAIMER APX 7.4 ‚Äî Dynamic Workload Adaptation**

APX 7.4 ‚Äî Dynamic Workload Adaptation no cambia kernels, no altera la matem√°tica, no toca forward/backward, ni modifica tensores reales. La adaptaci√≥n se limita exclusivamente a seleccionar cu√°ntos hilos y qu√© scheduler usar (Seq / PEX / WS) en base a la carga externa del sistema, pero siempre ejecutando los mismos operadores MatMul originales. Es totalmente segura, no invasiva y reversible.

---

## üü¶ APX 7.5 ‚Äî HPGE (Hierarchical Parallel Graph Executor)

- ‚úî Primer scheduler paralelo a nivel de grafo (`Graph`), por encima de `execute_single`.
- ‚úî Construye una topolog√≠a simple (padres/hijos) y ejecuta waves de nodos `ready`.
- ‚úî S√≥lo reordena nodos independientes; respeta estrictamente las dependencias.
- ‚úî Fallback seguro a `run_plan(true)` si detecta inconsistencias.

**DISCLAIMER APX 7.5 ‚Äî HPGE**

APX 7.5 no introduce kernels nuevos, no cambia la matem√°tica de los nodos, no altera backward, ni modifica la representaci√≥n interna de tensores. El Hierarchical Parallel Graph Executor s√≥lo decide el orden en el que se invoca `Graph::execute_single` sobre nodos que ya est√°n listos (sin padres pendientes), respetando 100% las dependencias topol√≥gicas. Si en cualquier momento detecta un estado inconsistente (ciclos, nodos no ejecutados, ausencia de nodos ready en un grafo no vac√≠o), hace fallback inmediato a la ejecuci√≥n secuencial est√°ndar mediante `run_plan(true)`.

---

## üü¶ APX 7.6 / 7.7 ‚Äî HPGE v2 + HPFA (Critical-Path Optimizer)

- ‚úî Extiende HPGE con un modelo de prioridad por nodo (Critical-Path Optimizer).
- ‚úî Se√±ales de prioridad: coste estimado, tama√±o de sub√°rbol, tiempo hist√≥rico y afinidad de fusi√≥n (HPFA).
- ‚úî Integra Hot-Path Fusion Awareness (APX 7.7) como bonificaci√≥n de prioridad; no toca fusiones reales.
- ‚úî Mantiene las mismas garant√≠as de HPGE: s√≥lo reordena nodos independientes.

**DISCLAIMER APX 7.6 / 7.7 ‚Äî HPGE v2 + HPFA**

APX 7.6/7.7 no introducen kernels nuevos ni cambian los existentes. No modifican backward, ni la cinta de autograd, ni la estructura del grafo. El Critical-Path Optimizer usa m√©tricas est√°ticas (coste estimado, tama√±o del sub√°rbol) e hist√≥ricas (tiempos medios por nodo) junto con la afinidad de fusi√≥n de APX 6.9/6.10 (HPFA) exclusivamente para ordenar el conjunto de nodos `ready`. Las dependencias topol√≥gicas se respetan en todo momento y, ante cualquier anomal√≠a, el sistema cae de vuelta a `run_plan(true)`.

---

## üü¶ APX 7.8 ‚Äî TLO (Temporal Locality Optimizer)

- ‚úî Introduce hints de localidad temporal por nodo (`branch_id`, `depth`) en `Graph::build`.
- ‚úî Reordena el conjunto de nodos `ready` seg√∫n estos hints antes de ejecutar cada batch.
- ‚úî No cambia el grafo ni sus dependencias; s√≥lo el orden de nodos independientes.
- ‚úî Se integra de forma transparente sobre HPGE / HPGE v2.

**DISCLAIMER APX 7.8 ‚Äî TLO**

APX 7.8 no modifica kernels, no altera la matem√°tica de forward/backward, ni cambia la representaci√≥n de tensores. El Temporal Locality Optimizer se limita a reordenar nodos que ya son independientes bas√°ndose en hints de localidad sint√©ticos derivados de la estructura del grafo (profundidad aproximada y rama l√≥gica). Todos los tests de equivalencia deben seguir pasando, y ante cualquier comportamiento sospechoso siempre es posible desactivar TLO o forzar el uso de `run_plan(true)`.

---

## üü¶ APX 7.9 ‚Äî HLS (Hierarchical Locality Scheduler)

- ‚úî Agrupa nodos en clusters jer√°rquicos seg√∫n su firma estructural (n√∫mero de padres/hijos).
- ‚úî Refina clusters por localidad: inputs compartidos, padre com√∫n, mismo tipo de op.
- ‚úî Ordena clusters por score, tama√±o y fanout para guiar el scheduler de prioridades.
- ‚úî No modifica kernels ni backward; s√≥lo aporta un orden jer√°rquico adicional.

**DISCLAIMER APX 7.9 ‚Äî HLS**

APX 7.9 no a√±ade operadores nuevos ni toca la matem√°tica de las operaciones existentes. El Hierarchical Locality Scheduler s√≥lo construye una agrupaci√≥n l√≥gica de nodos (clusters) basada en informaci√≥n estructural del grafo y la usa como hint adicional para priorizar nodos `ready` dentro de HPGE v2. No se alteran dependencias, no se introducen nuevos caminos de ejecuci√≥n, y el sistema mantiene la posibilidad de caer en `run_plan(true)` si la topolog√≠a calculada resultara inconsistente.

---

## üü¶ APX 7.10 ‚Äî HLS-Deep (Deep SuperLevel Scheduling)

- ‚úî Calcula profundidades topol√≥gicas por nodo y construye SuperLevels por anchura/profundidad.
- ‚úî Ejecuta SuperLevels secuencialmente y nodos dentro de cada uno en paralelo (o en batch ordenado).
- ‚úî Integra TLO como heur√≠stica de orden dentro de SuperLevels anchos.
- ‚úî Mantiene equivalencia num√©rica con la ejecuci√≥n cl√°sica / HPGE.

**DISCLAIMER APX 7.10 ‚Äî HLS-Deep**

APX 7.10 no introduce kernels nuevos, no altera backward ni la forma de los tensores. El HLS Deep Pass s√≥lo reagrupa nodos en "SuperLevels" y decide el orden de llamada a `execute_single` dentro de cada uno, respetando siempre las dependencias topol√≥gicas originales del grafo. Si el algoritmo de construcci√≥n de SuperLevels o el scheduler interno detectan una situaci√≥n incoherente (por ejemplo, nodos que nunca llegan a estar listos), se activa un fallback inmediato a la ruta secuencial cl√°sica (`run_plan(true)`), preservando la correcci√≥n.

---

## üü¶ APX 7.11 ‚Äî PFLS (Predictive Future-Level Scheduling)

- ‚úî Registra tiempos y congesti√≥n por SuperLevel en un historial ligero (`PFLSHistory`).
- ‚úî Predice futuros "hotspots" (SuperLevels con mayor tiempo/congesti√≥n acumulados).
- ‚úî Reordena nodos en SuperLevels previos para despejar cuellos de botella futuros.
- ‚úî No usa datos reales del modelo; s√≥lo m√©tricas estructurales de ejecuci√≥n.

**DISCLAIMER APX 7.11 ‚Äî PFLS**

APX 7.11 PFLS no modifica kernels, matem√°ticas, backward ni la representaci√≥n interna de tensores. El sistema observa √∫nicamente tiempos de ejecuci√≥n por SuperLevel y el n√∫mero de nodos activos para predecir posibles cuellos de botella futuros y reordenar nodos independientes en niveles previos. Todas las dependencias topol√≥gicas se respetan estrictamente y, si la heur√≠stica predictiva detecta un estado inconsistente o no confiable, el sistema cae inmediatamente en la ruta segura de HPGE/HLS secuencial (`run_plan(true)`). PFLS nunca utiliza valores de tensores ni informaci√≥n de datos del modelo, s√≥lo tiempos y congesti√≥n estructural.

---

## üü¶ APX 7.12 ‚Äî ULE (Unified Level Executor)

- ‚úî Unifica en un solo m√≥dulo las heur√≠sticas de scheduling introducidas en 7.5‚Äì7.11.
- ‚úî Usa SuperLevels (HLS-Deep), TLO, prioridades estructurales y PFLS en una misma ruta.
- ‚úî Selecciona autom√°ticamente la "estrategia" (Seq / PEX / Work-Stealing) m√°s adecuada por SuperLevel.
- ‚úî Reemplaza en tiempo de ejecuci√≥n a HPGE/HLS/HLS-Deep/PFLS, manteniendo los m√≥dulos previos para tests.

**DISCLAIMER APX 7.12 ‚Äî ULE**

APX 7.12 no incorpora kernels nuevos, no cambia la matem√°tica, no altera backward ni la representaci√≥n de tensores. El Unified Level Executor se limita a unificar la l√≥gica de scheduling de APX 7.5‚Äì7.11 en un √∫nico m√≥dulo estructural que decide, por SuperLevel, c√≥mo ordenar y ejecutar nodos independientes. Las dependencias topol√≥gicas del grafo se respetan en todo momento y, ante cualquier inconsistencia detectada, el sistema realiza fallback inmediato a la ejecuci√≥n secuencial est√°ndar (`run_plan(true)`). PFLS sigue usando exclusivamente tiempos y congesti√≥n estructural; no se emplea informaci√≥n de datos reales del modelo.

---

## üü¶ APX 8.x ‚Äî GPU Simulation Stack (CPU-only)

- ‚úî Introduce una cadena completa de **infraestructura GPU simulada**: desde IR y registros de kernels hasta planificaci√≥n de dispositivo, partici√≥n, codegen y orquestaci√≥n h√≠brida.
- ‚úî Todos los m√≥dulos APX 8.x funcionan **exclusivamente sobre CPU**, generando strings y metadatos; **no hay llamadas reales a CUDA/HIP/Metal/Vulkan**, ni reservas de VRAM.
- ‚úî No se modifican kernels CPU existentes, ni rutas de `Tensor`, ni backward/autograd; toda la l√≥gica GPU es simb√≥lica y reversible.
- ‚úî Cada subversi√≥n 8.x a√±ade una capa estructural: dual graph, dispatcher h√≠brido, estimadores de transferencia, mirror/persistencia, registro de kernels, IR, codegen mock, router multi-arch, planners de dispositivo/partici√≥n y un orquestador h√≠brido (HXO).

**DISCLAIMER APX 8.x ‚Äî GPU Simulation Stack**

APX 8.x no ejecuta kernels GPU reales, no reserva memoria de dispositivo, no realiza transferencias H2D/D2H reales, no modifica la matem√°tica de los kernels CPU ni altera backward ni la cinta de autograd. Toda la infraestructura de GPU introducida en 8.1‚Äì8.20 es puramente simb√≥lica: construye grafos duales, estima costes de transferencia, mantiene espejos y metadatos de persistencia, registra kernels y firmas, genera IR y c√≥digo mock (strings), simula routers multi-arch y planificadores de dispositivo/partici√≥n, y finalmente orquesta un "HybridOpPlan" mediante HXO. Los tensores reales siguen viviendo y operando en CPU; todos los tests de APX 8.x incluyen comprobaciones expl√≠citas de **equivalencia num√©rica** frente a las rutas anteriores.

### APX 8.1‚Äì8.5 ‚Äî Dual Graph, Hybrid Dispatcher y Estado GPU simb√≥lico

- **8.1 DualGraph Builder (`apx8::dualgraph`)**
  - Construye un grafo dual CPU/GPU duplicando nodos y manteniendo mapeos entre ellos.
  - Uso: puramente estructural, base para dispatchers posteriores.
- **8.2 Hybrid Dispatcher (`apx8::hybrid_dispatcher`)**
  - `ExecDevice::{CPU,GPU}` y `HybridDispatcher::dispatch` deciden simb√≥licamente CPU vs GPU.
  - La ruta GPU llama a `exec_gpu_stub`, que internamente ejecuta la misma ruta CPU (`execute_single_inner`).
- **8.3 GPU Transfer Estimator (`apx8::gpu_transfer_estimator`)**
  - `GPUTransferEstimator::estimate` devuelve un `TransferEstimate` sint√©tico seg√∫n tama√±o de tensor y `DevicePlacement`.
  - `HybridDispatcher::choose_device_for` usa ese criterio para mejorar la decisi√≥n CPU/GPU sin mover datos.
- **8.4 GPU Mirroring Layer (`apx8::mirror`)**
  - A√±ade `GPUMirror` y `MirrorState` como marca de espejo GPU en `Tensor` (campo `gpu: Option<GPUMirror>`).
  - No copia buffers a GPU; s√≥lo marca estados logical-clean/dirty.
- **8.5 GPU Persistence Layer (`apx8::persistent`)**
  - Introduce `GPUPersistenceInfo` y un contador global de pasos para heur√≠sticas de reutilizaci√≥n y limpieza del mirror.
  - Integrado en `Tensor` como `persistence: Option<GPUPersistenceInfo>`.

### APX 8.6‚Äì8.12 ‚Äî Kernels simulados, Registry, IR y MetaLayer

- **8.6 GPU Kernels v0 (`apx8::gpu_kernels`)**
  - Define un kernel stub `gpu_vec_add` que opera sobre datos CPU y marca el mirror GPU como dirty.
  - Controlado por `RuntimeFlags::enable_gpu_kernels`.
- **8.7 Kernel Registry v1 (`apx8::kernel_registry`)**
  - `KernelRegistry`, `KernelKey`, `KernelFn` y `RegisteredKernel`.
  - Registra kernels CPU y stubs GPU, as√≠ como plantillas de kernels (`GpuKernelTemplate`).
- **8.8 GPU Kernel Signatures v0 (`apx8::gpu_kernel_signature`)**
  - Registra firmas textuales `GpuKernelSignature` para diferentes tipos de kernels GPU.
  - Sirve como capa de identificaci√≥n/metadata, sin ejecuci√≥n real.
- **8.9 GPU Kernel Generators v0 + 8.12 KernelIR (`apx8::kernel_generator`)**
  - V0: `GpuKernelOp`, `GpuKernelTemplate` ‚Üí `GpuKernelIR` v√≠a `to_ir()`.
  - 8.12: `KernelOp` y `KernelIR { ops, name, params }` con `mock_add`, `new_mock`, `hash`, `signature`.
  - Este `KernelIR` es la representaci√≥n central usada por el resto de la pipeline GPU simulada.
- **8.12 GPU MetaLayer (`apx8::gpu_metalayer`)**
  - `optimize_ir(ir)` produce un `OptimizedIR` simb√≥lico (p.ej., filtrando NOPs).
  - No altera ejecuci√≥n real; s√≥lo reescribe IR.

### APX 8.10‚Äì8.17 ‚Äî Codegen Mock, Compiler Stub, Router y Finalizer

- **8.10 GPU Codegen Mock (`apx8::codegen_mock`)**
  - Implementa el trait `GpuCodegen` para backends sint√©ticos (CUDA, HIP, Metal) que producen c√≥digo como string, sin compilaci√≥n real.
- **8.11 GPU Compiler Stub (`apx8::gpu_compiler_stub`)**
  - `GpuCompilerStub` mantiene un cache de `CompiledKernelStub` indexado por `GpuTarget` y firmas.
  - Simula la existencia de un compilador/driver sin tocar hardware.
- **8.13 GPU Codegen v1 (`apx8::codegen::gpu_codegen_v1`)**
  - `GPUCodegenV1` genera c√≥digo sint√©tico a partir de `KernelIR` mediante `generate_kernel`.
  - `with_autoselect` usa `GPUAutoSelector` (8.14) y normaliza vendors (`"nvidia"`, `"amd"`, `"intel"`) a `"cuda"`, `"hip"`, `"metal"`.
  - `codegen_with_cache` integra `PrecompileCache` (8.15) como cache de strings.
  - `codegen_multiarch` usa `route_kernel` (8.16) para anotar la arquitectura seleccionada.
  - `codegen_with_finalizer` combina `generate_kernel` con `gpu_finalize` (8.17).
- **8.14 GPU Auto-Selector v0 (`apx8::gpu_autoselector`)**
  - `GPUAutoSelector::detect` y `choose_backend(ir)` seleccionan un backend textual seg√∫n el nombre del IR.
  - No inspecciona hardware real; es un heur√≠stico determinista.
- **8.15 Pre-Compilation Cache v0 (`apx8::precompile_cache`)**
  - `PrecompileCache` guarda strings `compiled::<signature>` por `KernelIR`.
  - Usado en rutas como `codegen_with_cache` para simular kernels ya compilados.
- **8.16 Multi-Arch Kernel Routing v0 (`apx8::multiarch_router`)**
  - `TargetArch` y `route_kernel(ir)` determinan simb√≥licamente si el IR ir√≠a a CPU, CUDA, HIP, Metal o Vulkan seg√∫n su firma.
- **8.17 GPU Finalizer Stub (`apx8::gpu_finalizer`)**
  - `gpu_finalize(ir)` genera strings como `"FINALIZED CUDA KERNEL for {name}"` o `"CPU fallback"` seg√∫n `TargetArch`.
  - Se integra en `GPUCodegenV1::codegen_with_finalizer` como √∫ltima etapa simb√≥lica.

### APX 8.18‚Äì8.20 ‚Äî Device Planner, Partitioning Simulator y HXO

- **8.18 GPU Device Planner v0 (`apx8::device_planner`)**
  - `SimulatedGPU` y `DevicePlan` describen dispositivos y hints de split totalmente ficticios.
  - `detect_simulated_gpus` devuelve GPUs fake (ej. `FakeCUDA_4090`).
  - `plan_for_ir(ir_name)` decide simb√≥licamente si un IR se asociar√≠a a una GPU concreta o a CPU.
- **8.19 GPU Partitioning Simulator (GPS) (`apx8::gpu_partition`)**
  - `PartitionPolicy` y `PartitionPlan` definen pol√≠ticas 1D/2D/Auto basadas en la forma de un tensor (`shape`).
  - `suggest_partition(shape)` devuelve una pol√≠tica y un `estimated_speedup` puramente simb√≥lico.
  - `HybridDispatcher::choose_gpu_strategy(shape)` usa esta funci√≥n para describir una estrategia, sin particionar datos reales.
- **8.20 Hybrid Execution Orchestrator (HXO) (`apx8::hxo`)**
  - `HybridOpPlan` agrega en una sola estructura: `device`, `partition`, `backend`, `codegen` y un flag `precompiled`.
  - `build_hxo_plan(ir, shape)` orquesta:
    - planner de dispositivo (8.18), planner de partici√≥n (8.19), router multi-arch (8.16), cache de precompilaci√≥n (8.15) y codegen+finalizer (8.13+8.17).
  - `hybrid_dispatch(ir, shape)` expone un `HybridDispatchResult::Pseudo` s√≥lo con metadatos, sin tocar `Graph` ni `Tensor`.

En conjunto, APX 8.x prepara una cadena GPU completa a nivel de arquitectura ‚Äîgrafo dual, dispatch h√≠brido, IR, registros, codegen, planners y orquestador‚Äî mientras mantiene la ejecuci√≥n real estrictamente en CPU y num√©ricamente equivalente a las versiones previas.

---

## üü¶ APX 9.x ‚Äî Virtual GPU Pipeline & SM Model

La fase APX 9.x est√° **completamente implementada** de la 9.1 a la 9.25 e introduce una pila de simulaci√≥n GPU de nivel arquitectural, todav√≠a 100% CPU-only:

- **APX 9.1‚Äì9.5**
  - IR GPU de alto nivel, generaci√≥n de PTX simb√≥lico y toolchain de validaci√≥n/optimizaci√≥n (PTX emitter, validator, traductor SASS, optimizador SASS).

- **APX 9.6‚Äì9.10**
  - Planificador de memoria GPU simulado, planificador de ejecuci√≥n, ejecutor GPU mock, autotuner basado en tiempos simulados y codegen GPU real stub (orientado a APX 10).

- **APX 9.11‚Äì9.14**
  - Traductor CPU‚ÜíPTX, ejecutor vGPU de alto nivel, modelo de memoria virtual (`VGpuMemory`) y runner vGPU (`VGpuRunner`) que ejecuta el IR sobre CPU.

- **APX 9.15‚Äì9.19**
  - Lanzador de bloques (`VGpuBlockLauncher`), capa de sincronizaci√≥n (`VGPUBarrier` / `VGPUBlockContext`), modelo SIMT de warp (`VGPUWarp`), scheduler de warps y pila de divergencia/reconvergencia (`WarpMask`, `DivergenceStack`).

- **APX 9.20‚Äì9.23**
  - Pipeline SIMT Fetch/Decode/Execute (`VGPUPipeline`), scoreboard de registros (`VGPUScoreboard`), out‚Äëof‚Äëorder warp scheduler (`VGPUOOWarpScheduler`) y unidad de dual‚Äëissue simb√≥lica (`VGPUDualIssue`).
